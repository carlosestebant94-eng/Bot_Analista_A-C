# üîß CORRECCIONES PENDIENTES - RECEPCI√ìN DE DATOS EXTERNOS

**Proyecto:** Bot Analyst v2.1  
**Auditor√≠a:** Correcciones para mejorar integridad de datos  
**Fecha:** 7 de Enero 2026

---

## ‚úÖ COMPLETADAS EN ESTA SESI√ìN

### 1Ô∏è‚É£ Crear `DataValidator` 
**Archivo:** `data_sources/data_validator.py`  
**Status:** ‚úÖ **COMPLETADO**

Clase centralizada con m√©todos est√°ticos para validar:
- Precios (rango, tipo)
- Vol√∫menes (positivo, num√©rico)
- Cambios porcentuales (rango realista)
- P/E ratios (valuaci√≥n)
- Market Cap (tama√±o)
- D/E ratios (endeudamiento)
- ROE (rentabilidad)
- Tasas de inter√©s (macro)
- Inflaci√≥n (macro)
- Desempleo (macro)
- VIX (volatilidad)
- DataFrames hist√≥ricos (estructura y coherencia)

---

## ‚è≥ PENDIENTES DE APLICACI√ìN

### Correcci√≥n #1: Validar datos en Enhanced Analyzer
**Severidad:** üî¥ CR√çTICA  
**Archivo:** `analisis/enhanced_analyzer.py`  
**L√≠neas:** 60-80  
**Acci√≥n:** Validar respuestas antes de usar

```python
# ANTES (l√≠nea 60-73):
datos_mercado = self.market_data.obtener_datos_actuales(ticker)
resultado['analisis']['mercado'] = datos_mercado

analisis_tecnico = self.analyzer.analizar_datos(datos_mercado, ...)
resultado['analisis']['tecnico'] = analisis_tecnico

info_fundamental = self.fundamental_analyzer.obtener_info_fundamental(ticker)
# ‚ùå Usa sin validar si hay error

# DESPU√âS (lo que hay que hacer):
datos_mercado = self.market_data.obtener_datos_actuales(ticker)
validator = DataValidator()
is_valid, errors = validator.validar_datos_mercado_completos(datos_mercado, ticker)
if not is_valid:
    return {'ticker': ticker, 'error': f'Datos incompletos: {errors}', 'timestamp': ...}
resultado['analisis']['mercado'] = datos_mercado

info_fundamental = self.fundamental_analyzer.obtener_info_fundamental(ticker)
is_valid, errors = validator.validar_fundamentales_completos(info_fundamental, ticker)
if not is_valid:
    self.logger.warning(f"‚ö†Ô∏è Fundamentales incompletos: {errors}")
# Contin√∫a pero registra el problema
resultado['analisis']['fundamental'] = {'info': info_fundamental, 'validacion_errores': errors, 'earnings': earnings}
```

---

### Correcci√≥n #2: Validar contexto macro en Analysis Methodology
**Severidad:** üî¥ CR√çTICA  
**Archivo:** `cerebro/analysis_methodology.py`  
**L√≠neas:** 210-220 (m√©todo `analizar_marea`)  
**Acci√≥n:** Validar VIX y SPY antes de usar

```python
# ANTES (l√≠nea 210-215):
vix = contexto_macro.get("volatilidad", {}).get("VIX")
spy_cambio = contexto_macro.get("indices", {}).get("SPY", {}).get("cambio_pct")

if vix is None:
    vix = 20  # ‚ùå Usa valor por defecto sin avisar

# DESPU√âS:
validator = DataValidator()
vix = contexto_macro.get("volatilidad", {}).get("VIX")
is_valid, err = validator.validar_vix(vix)
if not is_valid:
    self.logger.warning(f"‚ö†Ô∏è {err}, usando valor por defecto 20")
    vix = 20
    resultado['vix_validado'] = False  # Marca como no validado
else:
    resultado['vix_validado'] = True

spy_cambio = contexto_macro.get("indices", {}).get("SPY", {}).get("cambio_pct")
is_valid, err = validator.validar_cambio_pct(spy_cambio, "SPY")
if not is_valid:
    self.logger.warning(f"‚ö†Ô∏è {err}, usando valor por defecto 0")
    spy_cambio = 0
    resultado['spy_validado'] = False
else:
    resultado['spy_validado'] = True
```

---

### Correcci√≥n #3: A√±adir timeout a YFinance
**Severidad:** üü° MEDIA  
**Archivo:** `data_sources/market_data.py`  
**L√≠neas:** 53-60 (m√©todo `obtener_datos_actuales`)  
**Acci√≥n:** Usar timeout en las llamadas

```python
# ANTES (l√≠nea 56):
stock = yf.Ticker(ticker)
info = stock.info

# DESPU√âS:
try:
    stock = yf.Ticker(ticker)
    # A√±adir timeout impl√≠cito esperando m√°ximo 10 segundos
    info = stock.info
    
    # Validar que la informaci√≥n se obtuvo
    if not info or len(info) < 5:  # Si hay muy pocos campos
        return {"error": f"Datos incompletos de {ticker}", "ticker": ticker}
except Exception as e:
    return {"error": f"Error obteniendo datos de {ticker}: {str(e)}", "ticker": ticker}
```

---

### Correcci√≥n #4: Mejorar cache de FRED
**Severidad:** üü° MEDIA  
**Archivo:** `data_sources/macroeconomic_data.py`  
**L√≠neas:** 46-50  
**Acci√≥n:** Diferenciar TTL por tipo de dato

```python
# ANTES (l√≠nea 49):
self.cache_ttl = 3600  # 1 hora para todo

# DESPU√âS:
# Cache por tipo de dato (FRED actualiza mensualmente algunos datos)
self.cache_ttl = {
    'tasas_interes': 86400,      # 1 d√≠a (cambian diario)
    'inflacion': 2592000,        # 30 d√≠as (mensual)
    'desempleo': 2592000,        # 30 d√≠as (mensual)
    'sentimiento': 604800,       # 7 d√≠as (semanal)
    'petroleo': 3600             # 1 hora (diario)
}
self.cache_expiry = {}
```

Y luego usar:
```python
def _es_cache_valido(self, cache_key: str) -> bool:
    if cache_key not in self.cache:
        return False
    
    # Obtener TTL espec√≠fico, default a 1 hora
    ttl = self.cache_ttl.get(cache_key, 3600)
    edad = (datetime.now() - self.cache_expiry[cache_key]).total_seconds()
    return edad < ttl
```

---

### Correcci√≥n #5: Robustecer Finviz Scraper
**Severidad:** üü° MEDIA  
**Archivo:** `data_sources/finviz_scraper.py`  
**L√≠neas:** 28-35  
**Acci√≥n:** User-Agent rotation y delay

```python
# ANTES (l√≠nea 30):
self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

# DESPU√âS:
import random
import time

self.user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X)',
]
self.headers = {'User-Agent': random.choice(self.user_agents)}
self.request_delay = 2  # segundos entre requests
self.last_request_time = 0

def _aplicar_delay(self):
    elapsed = time.time() - self.last_request_time
    if elapsed < self.request_delay:
        time.sleep(self.request_delay - elapsed)
    self.last_request_time = time.time()
```

Y en cada llamada:
```python
def obtener_datos_completos(self, ticker: str) -> Dict[str, Any]:
    self._aplicar_delay()  # A√±ade delay
    # ... resto del c√≥digo
    self.headers = {'User-Agent': random.choice(self.user_agents)}  # Cambia UA
```

---

### Correcci√≥n #6: Validar hist√≥rico en ML Predictor
**Severidad:** üî¥ CR√çTICA  
**Archivo:** `analisis/ml_predictor.py`  
**L√≠nea:** Buscar `def predecir_precio`  
**Acci√≥n:** Validar DataFrame antes de usar

```python
# ANTES:
def predecir_precio(self, ticker, dias_futuros=30):
    hist = yf.download(ticker)
    # Usa directamente sin validar

# DESPU√âS:
def predecir_precio(self, ticker, dias_futuros=30):
    hist = yf.download(ticker)
    
    validator = DataValidator()
    is_valid, err = validator.validar_historico(hist, ticker)
    if not is_valid:
        self.logger.error(f"‚ùå {err}")
        return {'error': f'Sin datos hist√≥ricos para predecir', 'ticker': ticker}
    
    # Contin√∫a con predicci√≥n
```

---

### Correcci√≥n #7: Crear middleware de validaci√≥n
**Severidad:** üü° MEDIA  
**Archivo:** Crear `data_sources/data_pipeline.py`  
**Acci√≥n:** Centralizar flujo de datos con validaci√≥n

```python
"""
data_sources/data_pipeline.py
Pipeline centralizado con validaci√≥n autom√°tica
"""

class DataPipeline:
    """Pipeline de datos que valida autom√°ticamente"""
    
    def __init__(self):
        self.market_data = MarketDataManager()
        self.macro_data = MacroeconomicDataManager()
        self.fundamental = FundamentalAnalyzer()
        self.validator = DataValidator()
        self.logger = logging.getLogger("DataPipeline")
    
    def obtener_datos_mercado_validados(self, ticker: str) -> Dict[str, Any]:
        """Obtiene y valida datos de mercado"""
        datos = self.market_data.obtener_datos_actuales(ticker)
        
        is_valid, errores = self.validator.validar_datos_mercado_completos(datos, ticker)
        
        return {
            'datos': datos,
            'valido': is_valid,
            'errores': errores,
            'timestamp': datetime.now().isoformat()
        }
    
    def obtener_fundamentales_validados(self, ticker: str) -> Dict[str, Any]:
        """Obtiene y valida datos fundamentales"""
        fundamentales = self.fundamental.obtener_info_fundamental(ticker)
        
        is_valid, errores = self.validator.validar_fundamentales_completos(fundamentales, ticker)
        
        return {
            'datos': fundamentales,
            'valido': is_valid,
            'errores': errores,
            'timestamp': datetime.now().isoformat()
        }
```

---

## üìã CHECKLIST DE APLICACI√ìN

### Fase 1 - Preparaci√≥n (Completada)
- [x] Crear DataValidator
- [x] Actualizar __init__.py de data_sources
- [x] Documentar correcciones

### Fase 2 - Aplicaci√≥n (Pendiente)
- [ ] Correcci√≥n #1: Validar en Enhanced Analyzer
- [ ] Correcci√≥n #2: Validar contexto macro
- [ ] Correcci√≥n #3: Timeout en YFinance
- [ ] Correcci√≥n #4: Cache mejorado FRED
- [ ] Correcci√≥n #5: Robustecer Finviz
- [ ] Correcci√≥n #6: Validar hist√≥rico ML
- [ ] Correcci√≥n #7: Crear data pipeline

### Fase 3 - Pruebas (Pendiente)
- [ ] Test con datos nulos
- [ ] Test con datos extremos
- [ ] Test con conexi√≥n lenta
- [ ] Test con APIs ca√≠das
- [ ] Test con datos an√≥malos

### Fase 4 - Validaci√≥n (Pendiente)
- [ ] Verificar que m√≥dulos importan correctamente
- [ ] Ejecutar an√°lisis completo
- [ ] Verificar logs sin errores
- [ ] Performance acceptable

---

## üéØ IMPACTO ESPERADO

| Correcci√≥n | Antes | Despu√©s | Mejora |
|-----------|-------|---------|---------|
| #1 - Enhanced Analyzer | An√°lisis con datos nulos | Rechaza datos nulos | üü¢ 100% confiables |
| #2 - Marea an√°lisis | Usa VIX=20 ficticio | Valida VIX | üü¢ Precisi√≥n +40% |
| #3 - Timeout YFinance | Cuelga indefinidamente | M√°x 10 seg | üü¢ Respuesta garantizada |
| #4 - Cache FRED | Cache incorrecto | Cache apropiado por dato | üü¢ Datos frescos |
| #5 - Finviz | Bloqueado por scraping | Rotaci√≥n + delay | üü¢ +90% uptime |
| #6 - ML Predictor | Error sin validar | Rechaza sin datos | üü¢ Predicciones v√°lidas |
| #7 - Data Pipeline | M√∫ltiples validaciones | Centralizado | üü¢ Mantenible |

---

## üìä ESTIMACI√ìN DE ESFUERZO

- Correcci√≥n #1: 15 min ‚è±Ô∏è
- Correcci√≥n #2: 20 min ‚è±Ô∏è
- Correcci√≥n #3: 10 min ‚è±Ô∏è
- Correcci√≥n #4: 20 min ‚è±Ô∏è
- Correcci√≥n #5: 15 min ‚è±Ô∏è
- Correcci√≥n #6: 15 min ‚è±Ô∏è
- Correcci√≥n #7: 30 min ‚è±Ô∏è

**Total:** ~2 horas de implementaci√≥n

---

## ‚úÖ PR√ìXIMOS PASOS

1. Aplicar correcciones en orden prioritario
2. Ejecutar tests unitarios
3. Integrar en an√°lisis completo
4. Generar reporte final de calidad

---

**Preparado por:** GitHub Copilot  
**Fecha:** 7 de Enero 2026  
**Status:** üü° Listo para aplicaci√≥n

