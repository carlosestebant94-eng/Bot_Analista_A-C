================================================================================
FASE 5B: DEPLOYMENT - INSTRUCCIONES PARA PROXIMA SESION
================================================================================

OBJETIVO: Integrar los adapters _integrated en main.py/bot.py y hacer go-live

DURACIÓN ESTIMADA: 30-45 minutos

================================================================================
PASO 1: BACKUP DE ARCHIVOS ORIGINALES
================================================================================

Antes de hacer cambios, crea backup de:
  [ ] telegram_bot/bot.py
  [ ] main.py (si existe)
  [ ] analisis/analyzer.py
  [ ] data_sources/market_data.py

Comando:
  cp telegram_bot/bot.py telegram_bot/bot.py.backup
  cp main.py main.py.backup

================================================================================
PASO 2: ACTUALIZAR IMPORTS EN MAIN/BOT
================================================================================

En telegram_bot/bot.py (o main.py):

CAMBIAR:
─────────────────────────────────────────────────────────────────────────────
from data_sources.market_data import MarketDataManager
from data_sources.macroeconomic_data import MacroeconomicDataManager
from analisis.analyzer import Analyzer
from analisis.ml_predictor import MLPredictor

A:
─────────────────────────────────────────────────────────────────────────────
from data_sources.market_data_integrated import MarketDataManagerIntegrated
from data_sources.macroeconomic_data_integrated import MacroeconomicDataManagerIntegrated
from analisis.analyzer_integrated import AnalyzerIntegrated
from analisis.ml_predictor_integrated import MLPredictorIntegrated
from logging_audit import setup_centralized_logging

REEMPLAZOS GLOBALES EN BOT.PY:
─────────────────────────────────────────────────────────────────────────────
MarketDataManager          → MarketDataManagerIntegrated
MacroeconomicDataManager   → MacroeconomicDataManagerIntegrated
Analyzer                   → AnalyzerIntegrated
MLPredictor                → MLPredictorIntegrated

================================================================================
PASO 3: INICIALIZAR LOGGING CENTRALIZADO
================================================================================

Agregar al INICIO de main() o __main__:

```python
if __name__ == "__main__":
    # Inicializar logging centralizado
    setup_centralized_logging("BotAnalyst", "INFO")
    
    # Resto del código...
    bot = BotAnalyst()
    bot.start()
```

Esto configurará:
  - Console logging (INFO+)
  - JSON structured logs
  - Error file logging
  - Performance tracking

================================================================================
PASO 4: INSTANCIAR NUEVOS ADAPTERS
================================================================================

En __init__ de BotAnalyst:

CAMBIAR:
─────────────────────────────────────────────────────────────────────────────
self.market = MarketDataManager(...)
self.macro = MacroeconomicDataManager()
self.analyzer = Analyzer()
self.ml = MLPredictor()

A:
─────────────────────────────────────────────────────────────────────────────
self.market = MarketDataManagerIntegrated(...)
self.macro = MacroeconomicDataManagerIntegrated()
self.analyzer = AnalyzerIntegrated()
self.ml = MLPredictorIntegrated()

NOTA: Los adapters heredan de los originals, así que API es 100% compatible

================================================================================
PASO 5: ACTUALIZAR LLAMADAS A MÉTODOS
================================================================================

Las llamadas originales siguen funcionando PERO ahora retornan UnifiedResponse:

ANTES (original):
─────────────────────────────────────────────────────────────────────────────
datos = self.market.obtener_datos_actuales("AAPL")
if "error" in datos:
    print(f"Error: {datos['error']}")
else:
    precio = datos["current_price"]

DESPUÉS (integrada):
─────────────────────────────────────────────────────────────────────────────
response = self.market.obtener_datos_actuales_integrated("AAPL")
if response.status == ResponseStatus.SUCCESS:
    precio = response.data.current_price
    print(f"Precio: ${precio} (cache_hit={response.cache_metadata.get('hit')})")
else:
    print(f"Error: {response.status}")
    for error in response.errors:
        print(f"  - {error}")

OPCIÓN SIMPLIFICADA (usar método original):
─────────────────────────────────────────────────────────────────────────────
# Los adapters MANTIENEN compatibilidad hacia atrás:
datos = self.market.obtener_datos_actuales("AAPL")  # Sigue funcionando
# Pero internamente usa cache + audit + performance tracking

================================================================================
PASO 6: TESTING LOCAL
================================================================================

Despues de cambios, ejecutar tests:

Test 1: Imports funcional
────────────────────────────────────────────────────────────────────────────
python -c "from telegram_bot.bot import BotAnalyst; print('OK')"

Test 2: Inicialización
────────────────────────────────────────────────────────────────────────────
python -c "
from telegram_bot.bot import BotAnalyst
from logging_audit import setup_centralized_logging
setup_centralized_logging('Test', 'INFO')
bot = BotAnalyst()
print('Bot initialized OK')
"

Test 3: Obtener datos
────────────────────────────────────────────────────────────────────────────
python -c "
from data_sources.market_data_integrated import MarketDataManagerIntegrated
from logging_audit import setup_centralized_logging
setup_centralized_logging('Test', 'INFO')
m = MarketDataManagerIntegrated()
r = m.obtener_datos_actuales_integrated('AAPL')
print(f'Status: {r.status}')
print(f'Cache hit: {r.cache_metadata.get(\"hit\")}')
"

Test 4: Performance stats
────────────────────────────────────────────────────────────────────────────
python -c "
from logging_audit import get_performance_monitor
perf = get_performance_monitor()
stats = perf.get_all_stats()
for op, data in stats.items():
    print(f'{op}: count={data[\"count\"]}, avg={data[\"average\"]:.2f}ms')
"

================================================================================
PASO 7: VALIDACIÓN DE LOGS
================================================================================

Verificar que logs se crean correctamente:

Ubicación: logs/audit/

Archivos esperados:
  - bot_data_fetch.jsonl (data fetches)
  - bot_analysis.jsonl (analysis results)
  - bot_errors.jsonl (errors)
  - bot_security.jsonl (security events)

Revisar contenido (debe ser JSON):
────────────────────────────────────────────────────────────────────────────
head -5 logs/audit/bot_data_fetch.jsonl

Debe mostrar JSON lines como:
{
  "timestamp": "2026-01-07T21:30:45.123456+00:00",
  "identifier": "AAPL",
  "source": "yfinance",
  "status": "success",
  "duration_ms": 245.67,
  ...
}

================================================================================
PASO 8: VERIFICAR CACHE FUNCTIONALITY
================================================================================

El caché debe mejorar performance significativamente:

Primera llamada (sin caché):
────────────────────────────────────────────────────────────────────────────
market.obtener_datos_actuales_integrated("AAPL")  # ~300-500ms

Segunda llamada (con caché):
────────────────────────────────────────────────────────────────────────────
market.obtener_datos_actuales_integrated("AAPL")  # ~1-2ms (cache hit)

Verificar en respuesta:
────────────────────────────────────────────────────────────────────────────
response.cache_metadata['hit']  # True en segunda llamada
response.cache_metadata['ttl']  # 3600 segundos

================================================================================
PASO 9: PREPARAR PARA PRODUCCIÓN
================================================================================

Antes de go-live:

[ ] Todos los tests pasen
[ ] Logs creándose correctamente
[ ] Cache funcionando
[ ] Performance verificado (75%+ mejora en latencia)
[ ] Error handling probado
[ ] Memory usage aceptable (<200MB)

Comandos útiles:
────────────────────────────────────────────────────────────────────────────
# Ver stats de cache
python -c "from cache import get_unified_cache; c=get_unified_cache(); print(c.get_stats())"

# Ver stats de performance
python -c "from logging_audit import get_performance_monitor; p=get_performance_monitor(); print(p.get_all_stats())"

# Limpiar logs viejos
rm -rf logs/audit/*.jsonl.*

================================================================================
PASO 10: DEPLOYMENT EN PRODUCCIÓN
================================================================================

Cuando esté lista:

[ ] Commit a git:
    git add data_sources/market_data_integrated.py
    git add data_sources/macroeconomic_data_integrated.py
    git add analisis/analyzer_integrated.py
    git add analisis/ml_predictor_integrated.py
    git add cache/__init__.py cache/unified_cache.py
    git add async_ops/
    git add logging_audit/
    git add telegram_bot/bot.py  (con imports actualizados)
    git commit -m "Phase 5A: Full integration of caching, async, and logging"

[ ] Deploy a Railway/Heroku:
    git push heroku main
    heroku logs --tail

[ ] Monitorear en vivo:
    - Ver logs: tail -f logs/audit/bot_*.jsonl
    - Ver performance: watch -n 5 'python check_performance.py'

================================================================================
TROUBLESHOOTING
================================================================================

PROBLEMA 1: ImportError: No module named 'xyz_integrated'
────────────────────────────────────────────────────────────────────────────
SOLUCIÓN:
  - Verificar que los archivos _integrated.py existen en directorios correctos
  - Ejecutar: python -m pytest TEST_INTEGRACION_SIMPLE.py

PROBLEMA 2: UnifiedResponse no tiene cierto atributo
────────────────────────────────────────────────────────────────────────────
SOLUCIÓN:
  - Verificar que response_schema.py tiene el atributo (con alias si es necesario)
  - Usar response.to_dict() para inspeccionar estructura

PROBLEMA 3: Cache no está persistiendo datos
────────────────────────────────────────────────────────────────────────────
SOLUCIÓN:
  - Verificar que database.sqlite existe en la carpeta
  - Ejecutar: rm database.sqlite && python (para recrear DB)

PROBLEMA 4: Logs no se crean
────────────────────────────────────────────────────────────────────────────
SOLUCIÓN:
  - Verificar que carpeta logs/audit/ existe (se crea automáticamente)
  - Verificar permisos de escritura en logs/
  - Ejecutar setup_centralized_logging() al inicio

================================================================================
TIEMPO ESTIMADO POR PASO
================================================================================

Paso 1 (Backup):              5 minutos
Paso 2 (Imports):             5 minutos
Paso 3 (Logging setup):        3 minutos
Paso 4 (Instanciar adapters):  2 minutos
Paso 5 (Actualizar llamadas):  5 minutos
Paso 6 (Testing local):        5 minutos
Paso 7 (Validar logs):         3 minutos
Paso 8 (Verificar cache):      3 minutos
Paso 9 (Pre-prod):             3 minutos
Paso 10 (Deployment):          5 minutos

TOTAL: ~40 minutos

================================================================================
INSTRUCCIONES PARA AGENTE (si continúa en próxima sesión)
================================================================================

Cuando usuario diga "continua con deployment" o similar:

1. Leer telegram_bot/bot.py
2. Identificar imports a cambiar
3. Ejecutar replacements de imports
4. Ejecutar replacements de clase names
5. Agregar setup_centralized_logging() al inicio
6. Ejecutar tests de validación
7. Mostrar resultados
8. Crear deployment checklist final

================================================================================
